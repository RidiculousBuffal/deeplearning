{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 初始化模型参数",
   "id": "8e3c13a4c9c50107"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:53:59.290544Z",
     "start_time": "2025-08-06T14:53:59.272425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "if is_cuda_available:\n",
    "    print(\"CUDA is available! PyTorch is using the GPU.\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU index: {torch.cuda.current_device()}\")\n",
    "    print(f\"Current GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    device = d2l.try_gpu(0)\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is using the CPU.\")"
   ],
   "id": "75ac2fb8bb7f4f98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! PyTorch is using the GPU.\n",
      "Number of GPUs available: 1\n",
      "Current GPU index: 0\n",
      "Current GPU name: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.738964Z",
     "start_time": "2025-08-06T14:43:04.704536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from d2l.torch import get_dataloader_workers, Animator\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root='../../data', train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root='../../data', train=False, transform=trans, download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=get_dataloader_workers()),\n",
    "            data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=get_dataloader_workers()))\n",
    "\n",
    "\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
   ],
   "id": "6a1018a10a287838",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.751095Z",
     "start_time": "2025-08-06T14:43:04.748071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10"
   ],
   "id": "e6b66481e3373c3b",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1.  **线性模型**：对于每个输入样本 $\\mathbf{x}$，模型会计算出它属于每个类别 $k$ 的一个“分数”（或称为 logit），记为 $o_k$。这个计算过程是线性的：\n",
    "    $$\n",
    "    \\mathbf{o} = \\mathbf{X}\\mathbf{W} + \\mathbf{b}\n",
    "    $$\n",
    "    其中：\n",
    "    *   $\\mathbf{X}$ 是输入特征矩阵，每一行是一个样本。\n",
    "    *   $\\mathbf{W}$ 是权重矩阵。\n",
    "    *   $\\mathbf{b}$ 是偏置向量。\n",
    "    *   $\\mathbf{o}$ 是输出的 logits 矩阵，每一行代表一个样本对应所有类别的分数。"
   ],
   "id": "e07639d453db95"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.781505Z",
     "start_time": "2025-08-06T14:43:04.775505Z"
    }
   },
   "source": [
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), device=device, requires_grad=True)\n",
    "b = torch.zeros(num_outputs, device=device, requires_grad=True)"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 定义softmax\n",
    "操作2.  **Softmax 函数**：得到这些分数后，直接比较大小是不够的，我们希望得到一个概率分布。Softmax 函数可以将这些任意实数的分数转换成一个概率分布，其中每个类别的概率值都在 (0, 1) 之间，且所有类别的概率之和为 1。对于单个样本的输出向量 $\\mathbf{o} = (o_1, o_2, ..., o_K)$，其 Softmax 变换后的概率向量 $\\hat{\\mathbf{y}}$ 中第 $i$ 个元素为：\n",
    "    $$\n",
    "    \\hat{y}_i = \\text{softmax}(\\mathbf{o})_i = \\frac{\\exp(o_i)}{\\sum_{j=1}^{K} \\exp(o_j)}\n",
    "    $$\n",
    "    其中 $K$ 是类别的总数。"
   ],
   "id": "ccdc015122baa3eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.845808Z",
     "start_time": "2025-08-06T14:43:04.841807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition"
   ],
   "id": "292fb32c73f887c4",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 定义模型",
   "id": "dbab58110fd0260e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.861489Z",
     "start_time": "2025-08-06T14:43:04.858205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape(-1, W.shape[0]), W) + b)"
   ],
   "id": "924a3a30aef03a7b",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 定义损失函数",
   "id": "789b750c0e50c692"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3.  **损失函数 (Cross-Entropy Loss)**：为了衡量模型预测的好坏，我们使用交叉熵损失函数。对于单个样本，其真实标签通常用 one-hot 向量 $\\mathbf{y}$ 表示（例如，如果真实类别是第 $c$ 类，则 $y_c=1$，其余 $y_j=0$）。损失函数定义为：\n",
    "    $$\n",
    "    L(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{j=1}^{K} y_j \\log(\\hat{y}_j)\n",
    "    $$\n",
    "    因为 $\\mathbf{y}$ 是 one-hot 向量，这个求和式可以简化为：\n",
    "    $$\n",
    "    L = -\\log(\\hat{y}_c)\n",
    "    $$\n",
    "    其中 $c$ 是该样本的真实类别索引。我们的目标就是最小化这个损失。\n"
   ],
   "id": "312c61dabd8ac03f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.878055Z",
     "start_time": "2025-08-06T14:43:04.873876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])"
   ],
   "id": "3262a29c742fa5d4",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 分类精度",
   "id": "ba9f609d60eee0fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.896803Z",
     "start_time": "2025-08-06T14:43:04.891804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        \"\"\"\n",
    "        如果 `y_hat` 的前两行是：`tensor([[0.1, 0.2, 0.7],  # 样本0，预测为类别2``[0.8, 0.1, 0.1]]) # 样本1，预测为类别0`经过 `y_hat.argmax(axis=1)` 后，`y_hat` 会变成：`tensor([2, 0])`\n",
    "        \"\"\"\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    \"\"\"\n",
    "    如果 `y_hat` (预测) 是 `tensor([2, 0])`，而 `y` (真实) 是 `tensor([2, 1])`。那么 `cmp` 的结果就是 `tensor([True, False])`。\n",
    "    \"\"\"\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    \"\"\"\n",
    "    接上一步，`cmp` 是 `tensor([True, False])`。\n",
    "    1.  `cmp.type(y.dtype)` 将其转换为 `tensor([1, 0])`。\n",
    "    2.  `.sum()` 对 `tensor([1, 0])` 求和，得到 `tensor(1)`。\n",
    "    3.  `float()` 将其转换为 `1.0`。\n",
    "    \"\"\"\n",
    "    return float(cmp.type(y.dtype).sum())\n"
   ],
   "id": "7c581a4c297a32ce",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "1.  **`net.eval()`**: 这是一个非常重要的步骤。当我们训练模型时，会使用 `net.train()` 模式，这会启用一些特定的层，比如 `Dropout`（随机丢弃神经元）和 `BatchNormalization`（使用当前批次的均值和方差）。但在评估和预测时，我们希望模型的行为是确定性的，不希望有随机性。`net.eval()` 会关闭 `Dropout`，并让 `BatchNormalization` 使用在整个训练集上学习到的全局均值和方差，从而保证评估结果的稳定和可复现。\n",
    "\n",
    "2.  **`metric = Accumulator(2)`**: 如上所述，这里创建了一个累加器，准备好两个位置。\n",
    "    *   `metric[0]` 将用于累加 **总的正确预测数**。\n",
    "    *   `metric[1]` 将用于累加 **总的样本数**。\n",
    "\n",
    "3.  **`for X, y in data_iter:`**: 这个循环会遍历 `data_iter`（比如 `test_iter`）中的所有数据，一次一个批次 (batch)。\n",
    "\n",
    "4.  **`metric.add(accuracy(net(X), y), y.numel())`**: 这是整个函数的心脏。对于当前的批次 `(X, y)`：\n",
    "    *   `net(X)`: 模型对输入 `X` 进行预测，得到概率矩阵 `y_hat`。\n",
    "    *   `accuracy(net(X), y)`: 调用我们之前分析过的 `accuracy` 函数，它会返回**当前这个批次中预测正确的样本数量**（一个整数）。\n",
    "    *   `y.numel()`: `y` 是当前批次的真实标签张量，`.numel()` 方法返回该张量中元素的总数，也就是**当前批次的大小**（batch size）。\n",
    "    *   `metric.add(...)`: 将这两个计算出的数值——“本批次正确数”和“本批次样本数”——传递给 `add` 方法，累加到 `metric` 中。\n",
    "\n",
    "5.  **`return metric[0] / metric[1]`**: 当 `for` 循环结束时，`metric` 已经遍历了整个数据集。\n",
    "    *   `metric[0]` 存储了所有批次正确数量的总和，即 $ \\text{Total Correct Predictions} $。\n",
    "    *   `metric[1]` 存储了所有批次样本数量的总和，即 $ \\text{Total Number of Samples} $。\n",
    "    *   两者相除，正好就是我们定义的分类精度公式：\n",
    "      $$\n",
    "      \\text{Accuracy} = \\frac{\\sum_{\\text{all batches}} \\text{correct\\_in\\_batch}}{\\sum_{\\text{all batches}} \\text{samples\\_in\\_batch}} = \\frac{\\text{Total Correct Predictions}}{\\text{Total Number of Samples}}\n",
    "      $$\n"
   ],
   "id": "46377f72437ab386"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.914182Z",
     "start_time": "2025-08-06T14:43:04.909828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_accuracy(net, data_iter, device=None): # 增加device参数\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "    metric = d2l.Accumulator(2)\n",
    "    \n",
    "    # 如果没有传入device，自动检测\n",
    "    if device is None:\n",
    "        device = next(iter(net.parameters())).device\n",
    "\n",
    "    for X, y in data_iter:\n",
    "        # 关键修改：将数据移动到GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ],
   "id": "62a1a4bcc21c2a6d",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.940697Z",
     "start_time": "2025-08-06T14:43:04.935699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Accumulator:  # @save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "\n",
    "    def __init__(self, n):\n",
    "        # 初始化一个长度为 n 的列表，所有元素都为 0.0\n",
    "        # 这 n 个位置将分别用于存储 n 个需要累加的变量\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        # 使用 *args 接收任意数量的参数\n",
    "        # zip会将 self.data 和 args 按位置配对\n",
    "        # 例如 self.data=[0,0], args=(10, 256) -> zip后为 [(0,10), (0,256)]\n",
    "        # 然后列表推导式会逐对相加, 更新 self.data\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        # 将所有累加的变量重置为 0\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 这是一个 \"魔术方法\", 让我们能像访问列表一样访问累加器的数据\n",
    "        # 例如,可以直接用 metric[0] 来获取第一个累加的变量\n",
    "        return self.data[idx]"
   ],
   "id": "8a4ea2f53599d19c",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "```python\n",
    "if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "else:\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "```\n",
    "\n",
    "*   这部分代码通过一个 `if/else` 结构，优雅地兼容了两种不同的优化方式。\n",
    "\n",
    "*   **分支一: 使用标准的 PyTorch 优化器 (`torch.optim.Optimizer`)**\n",
    "    *   `updater.zero_grad()`: **梯度清零**。由于 PyTorch 的梯度是累加的，所以在每次计算新一批数据的梯度前，必须将之前存储的梯度清零。\n",
    "    *   `l.mean().backward()`: **反向传播 (Backpropagation)**。这里先对批次中所有样本的损失 `l` 取平均值 (`.mean()`)，得到一个标量。然后调用 `.backward()`，PyTorch 的自动求导引擎会根据这个标量损失计算出模型中所有参数（`W` 和 `b`）的梯度。使用 `.mean()` 是标准做法，它使得学习率的选择与批次大小（batch size）无关。\n",
    "    *   `updater.step()`: **更新参数**。优化器根据计算出的梯度和预设的学习率，自动更新模型的所有参数。例如，对于随机梯度下降(SGD)，这一步执行的就是 $ \\mathbf{W} \\leftarrow \\mathbf{W} - \\eta \\nabla_{\\mathbf{W}} L $。\n",
    "\n",
    "*   **分支二: 使用我们从零开始实现的自定义 `updater` 函数**\n",
    "    *   `l.sum().backward()`: **反向传播**。这里对损失 `l` 进行求和 (`.sum()`)。这样做得到的梯度是整个批次损失之和的梯度，而不是平均损失的梯度。\n",
    "    *   `updater(X.shape[0])`: **更新参数**。调用我们自己写的 `updater` 函数。这个自定义函数需要手动实现参数更新的逻辑。它接收批次大小 `X.shape[0]` 作为参数。为什么需要这个参数？因为我们的梯度是基于损失之和计算的，所以在手动更新时，通常需要除以批次大小来得到平均梯度，即 $ \\mathbf{W} \\leftarrow \\mathbf{W} - \\eta \\frac{\\nabla_{\\mathbf{W}} L_{sum}}{\\text{batch\\_size}} $。将 `batch_size` 传进去就是为了完成这个除法。"
   ],
   "id": "ac8849e638aa3afb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:04.989442Z",
     "start_time": "2025-08-06T14:43:04.984569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch_ch3(net, train_iter, loss, updater, device=None): # 增加device参数\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    metric = Accumulator(3)\n",
    "    \n",
    "    # 如果没有传入device，自动检测\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        device = next(iter(net.parameters())).device\n",
    "\n",
    "    for X, y in train_iter:\n",
    "        # 关键修改：将数据移动到GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add(l.sum(), accuracy(y_hat, y), y.numel())\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ],
   "id": "82344e89cd37c8eb",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**分步解析**:\n",
    "\n",
    "1.  **`animator = Animator(...)`**: 在训练开始前，首先初始化一个 `Animator` 对象。\n",
    "    *   `xlabel='epoch'`: 设置图表的 x 轴标签为 'epoch'。\n",
    "    *   `xlim=[1, num_epochs]`: 设置 x 轴的显示范围从 1 到 `num_epochs`。\n",
    "    *   `ylim=[0.3, 0.9]`: 设置 y 轴的显示范围。这通常是根据经验预设的一个合理范围，用于观察损失和精度的变化。\n",
    "    *   `legend=['train loss', 'train acc', 'test acc']`: 这是**非常关键**的一步。它定义了图表中将要绘制的三条曲线的名称。这三条线将分别对应：训练损失、训练精度和测试精度。\n",
    "\n",
    "2.  **`for epoch in range(num_epochs):`**: 这是训练的主循环，它会迭代 `num_epochs` 次，每一次迭代代表一个完整的训练周期。\n",
    "\n",
    "3.  **`train_metrics = train_epoch_ch3(...)`**: 在循环内部，首先调用 `train_epoch_ch3` 函数。我们已经知道，这个函数会用全部训练数据对模型进行一次训练，并返回一个包含两个元素的元组 (tuple)：`(平均训练损失, 平均训练精度)`。这个元组被赋值给 `train_metrics`。\n",
    "\n",
    "4.  **`test_acc = evaluate_accuracy(...)`**: 在一个训练周期结束后，我们**立刻**在测试集 `test_iter` 上评估模型的性能。这至关重要，因为测试集精度（`test_acc`）是衡量模型**泛化能力**的核心指标。它可以帮助我们判断模型是否出现了过拟合（即在训练集上表现很好，但在未见过的数据上表现很差）。\n",
    "\n",
    "5.  **`animator.add(epoch + 1, train_metrics + (test_acc,))`**: 这是将当前周期的结果绘制到图表上的核心步骤。\n",
    "    *   `epoch + 1`: 这是 x 轴的坐标，代表当前的周期数（从 1 开始）。\n",
    "    *   `train_metrics + (test_acc,)`: 这是 y 轴的坐标。这里有一个巧妙的元组拼接操作：\n",
    "        *   `train_metrics` 是 `(train_loss, train_acc)`。\n",
    "        *   `(test_acc,)` 是一个只包含一个元素的元组。\n",
    "        *   两者相加得到一个新的元组：`(train_loss, train_acc, test_acc)`。\n",
    "    *   这个新元组中的三个值，恰好按顺序对应了我们在第 1 步中 `legend` 定义的三条曲线。`Animator` 会将这三个值分别添加到对应的曲线上，并更新图表。\n",
    "\n",
    "6.  **`train_loss, train_acc = train_metrics`**: 循环结束后，`train_metrics` 中保存的是**最后一个** epoch 的训练损失和训练精度。这里将其解包到两个独立的变量中。\n",
    "\n",
    "7.  **`assert ...`**: 断言语句。这是一种自动化的检查机制，用于验证训练结果是否达到了预期的基本标准。如果 `assert` 后面的条件为 `False`，程序会立即报错并显示相关信息。\n",
    "    *   `assert train_loss < 0.5`: 检查最终的训练损失是否足够低。\n",
    "    *   `assert train_acc > 0.7`: 检查最终的训练精度是否达到了一个可接受的水平。\n",
    "    *   `assert test_acc > 0.7`: 检查最终的测试精度是否也达到了可接受的水平。\n",
    "    *   这些断言是保证代码和模型按预期工作的良好实践。"
   ],
   "id": "2768c09935043b5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:05.010448Z",
     "start_time": "2025-08-06T14:43:05.005448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater, device): # 增加device参数\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        # 传递device\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater, device)\n",
    "        # 传递device\n",
    "        test_acc = evaluate_accuracy(net, test_iter, device)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc"
   ],
   "id": "d4795d05788fbf10",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:43:05.026440Z",
     "start_time": "2025-08-06T14:43:05.022442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr=0.1\n",
    "def updater(batch_size):\n",
    "    return d2l.sgd([W,b],lr,batch_size)"
   ],
   "id": "ab6e731c7a63e2c1",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_epochs=10\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater, device)"
   ],
   "id": "c8f9fee1ef6c776d",
   "execution_count": 88,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:46:09.444193Z",
     "start_time": "2025-08-06T14:46:04.370274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_ch3(net, test_iter, n=6, device=None):\n",
    "    \"\"\"预测标签（从零实现版本）\"\"\"\n",
    "    # 尝试从模型参数中自动推断设备，如果用户没有提供的话\n",
    "    if device is None:\n",
    "        device = next(iter(net.parameters())).device\n",
    "    for X, y in test_iter:\n",
    "        # 我们只需要一个批次的数据来进行可视化\n",
    "        break\n",
    "    trues = d2l.get_fashion_mnist_labels(y)\n",
    "    # 关键步骤：将输入数据 X 移动到模型所在的设备 (GPU)\n",
    "    X_on_gpu = X.to(device)\n",
    "    # 在GPU上进行预测，得到的结果也在GPU上\n",
    "    preds_on_gpu = net(X_on_gpu).argmax(axis=1)\n",
    "    preds = d2l.get_fashion_mnist_labels(preds_on_gpu.cpu())\n",
    "    titles = [true + '\\n' + pred for true, pred in zip(trues, preds)]\n",
    "    d2l.show_images(X[0:n].reshape(n, 28, 28), 1, n, titles=titles[0:n])\n",
    "predict_ch3(net,test_iter,device=device)"
   ],
   "id": "de71a94c69e31365",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 900x150 with 6 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"516.6pt\" height=\"114.698357pt\" viewBox=\"0 0 516.6 114.698357\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-08-06T22:46:09.420191</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.10.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 114.698357 \nL 516.6 114.698357 \nL 516.6 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 7.2 107.498357 \nL 78.942857 107.498357 \nL 78.942857 35.7555 \nL 7.2 35.7555 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#pca475d59d4)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"imagea3b98f64c4\" transform=\"scale(1 -1) translate(0 -72)\" x=\"7.2\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 7.2 107.498357 \nL 7.2 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 78.942857 107.498357 \nL 78.942857 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 7.2 107.498357 \nL 78.942857 107.498357 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 7.2 35.7555 \nL 78.942857 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_1\">\n    <!-- ankle boot -->\n    <g transform=\"translate(11.348304 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \nL 1159 4863 \nL 1159 1991 \nL 2875 3500 \nL 3609 3500 \nL 1753 1863 \nL 3688 0 \nL 2938 0 \nL 1159 1709 \nL 1159 0 \nL 581 0 \nL 581 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-61\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(61.279297 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6b\" transform=\"translate(124.658203 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(182.568359 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(210.351562 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(271.875 0)\"/>\n     <use xlink:href=\"#DejaVuSans-62\" transform=\"translate(303.662109 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(367.138672 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(428.320312 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(489.501953 0)\"/>\n    </g>\n    <!-- ankle boot -->\n    <g transform=\"translate(11.348304 29.7555) scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-61\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(61.279297 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6b\" transform=\"translate(124.658203 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(182.568359 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(210.351562 0)\"/>\n     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(271.875 0)\"/>\n     <use xlink:href=\"#DejaVuSans-62\" transform=\"translate(303.662109 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(367.138672 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(428.320312 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(489.501953 0)\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 93.291429 107.498357 \nL 165.034286 107.498357 \nL 165.034286 35.7555 \nL 93.291429 35.7555 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#pd7acce3d6a)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"image27b2cb6a4d\" transform=\"scale(1 -1) translate(0 -72)\" x=\"93.291429\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 93.291429 107.498357 \nL 93.291429 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 165.034286 107.498357 \nL 165.034286 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 93.291429 107.498357 \nL 165.034286 107.498357 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 93.291429 35.7555 \nL 165.034286 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_2\">\n    <!-- pullover -->\n    <g transform=\"translate(104.836607 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-70\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(63.476562 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(126.855469 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(154.638672 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(182.421875 0)\"/>\n     <use xlink:href=\"#DejaVuSans-76\" transform=\"translate(243.603516 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(302.783203 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(364.306641 0)\"/>\n    </g>\n    <!-- pullover -->\n    <g transform=\"translate(104.836607 29.7555) scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-70\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(63.476562 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(126.855469 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(154.638672 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(182.421875 0)\"/>\n     <use xlink:href=\"#DejaVuSans-76\" transform=\"translate(243.603516 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(302.783203 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(364.306641 0)\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_12\">\n    <path d=\"M 179.382857 107.498357 \nL 251.125714 107.498357 \nL 251.125714 35.7555 \nL 179.382857 35.7555 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#pafece25b34)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"image5ace7253da\" transform=\"scale(1 -1) translate(0 -72)\" x=\"179.382857\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 179.382857 107.498357 \nL 179.382857 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 251.125714 107.498357 \nL 251.125714 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 179.382857 107.498357 \nL 251.125714 107.498357 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 179.382857 35.7555 \nL 251.125714 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_3\">\n    <!-- trouser -->\n    <g transform=\"translate(193.812723 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-74\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(39.208984 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(78.072266 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(139.253906 0)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(202.632812 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(254.732422 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(316.255859 0)\"/>\n    </g>\n    <!-- trouser -->\n    <g transform=\"translate(193.812723 29.7555) scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-74\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(39.208984 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(78.072266 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(139.253906 0)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(202.632812 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(254.732422 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(316.255859 0)\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_4\">\n   <g id=\"patch_17\">\n    <path d=\"M 265.474286 107.498357 \nL 337.217143 107.498357 \nL 337.217143 35.7555 \nL 265.474286 35.7555 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#pde08cb9096)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"image58c686430d\" transform=\"scale(1 -1) translate(0 -72)\" x=\"265.474286\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 265.474286 107.498357 \nL 265.474286 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 337.217143 107.498357 \nL 337.217143 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 265.474286 107.498357 \nL 337.217143 107.498357 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 265.474286 35.7555 \nL 337.217143 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_4\">\n    <!-- trouser -->\n    <g transform=\"translate(279.904152 16.318125) scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-74\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(39.208984 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(78.072266 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(139.253906 0)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(202.632812 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(254.732422 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(316.255859 0)\"/>\n    </g>\n    <!-- trouser -->\n    <g transform=\"translate(279.904152 29.7555) scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-74\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(39.208984 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(78.072266 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(139.253906 0)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(202.632812 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(254.732422 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(316.255859 0)\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_5\">\n   <g id=\"patch_22\">\n    <path d=\"M 351.565714 107.498357 \nL 423.308571 107.498357 \nL 423.308571 35.7555 \nL 351.565714 35.7555 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#pfe9a7f4fde)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"image70096ec77d\" transform=\"scale(1 -1) translate(0 -72)\" x=\"351.565714\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 351.565714 107.498357 \nL 351.565714 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 423.308571 107.498357 \nL 423.308571 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 351.565714 107.498357 \nL 423.308571 107.498357 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 351.565714 35.7555 \nL 423.308571 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_5\">\n    <!-- shirt -->\n    <g transform=\"translate(374.023393 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-73\"/>\n     <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(52.099609 0)\"/>\n     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(115.478516 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(143.261719 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(184.375 0)\"/>\n    </g>\n    <!-- shirt -->\n    <g transform=\"translate(374.023393 29.7555) scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-73\"/>\n     <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(52.099609 0)\"/>\n     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(115.478516 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(143.261719 0)\"/>\n     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(184.375 0)\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_6\">\n   <g id=\"patch_27\">\n    <path d=\"M 437.657143 107.498357 \nL 509.4 107.498357 \nL 509.4 35.7555 \nL 437.657143 35.7555 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#pd8af7b6e9a)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"image1f25b70197\" transform=\"scale(1 -1) translate(0 -72)\" x=\"437.657143\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 437.657143 107.498357 \nL 437.657143 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 509.4 107.498357 \nL 509.4 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 437.657143 107.498357 \nL 509.4 107.498357 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 437.657143 35.7555 \nL 509.4 35.7555 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_6\">\n    <!-- trouser -->\n    <g transform=\"translate(452.087009 16.318125) scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-74\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(39.208984 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(78.072266 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(139.253906 0)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(202.632812 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(254.732422 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(316.255859 0)\"/>\n    </g>\n    <!-- trouser -->\n    <g transform=\"translate(452.087009 29.7555) scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-74\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(39.208984 0)\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(78.072266 0)\"/>\n     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(139.253906 0)\"/>\n     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(202.632812 0)\"/>\n     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(254.732422 0)\"/>\n     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(316.255859 0)\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pca475d59d4\">\n   <rect x=\"7.2\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n  </clipPath>\n  <clipPath id=\"pd7acce3d6a\">\n   <rect x=\"93.291429\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n  </clipPath>\n  <clipPath id=\"pafece25b34\">\n   <rect x=\"179.382857\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n  </clipPath>\n  <clipPath id=\"pde08cb9096\">\n   <rect x=\"265.474286\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n  </clipPath>\n  <clipPath id=\"pfe9a7f4fde\">\n   <rect x=\"351.565714\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n  </clipPath>\n  <clipPath id=\"pd8af7b6e9a\">\n   <rect x=\"437.657143\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 习题\n",
    "\n",
    "### 1. Softmax 的数值稳定性问题 (上溢)\n",
    "\n",
    "你直接根据数学定义实现的`softmax`函数如下：\n",
    "\n",
    "```python\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition\n",
    "```\n",
    "\n",
    "**问题所在：数值上溢 (Numerical Overflow)**\n",
    "\n",
    "当输入的`X`（通常是神经网络的输出，也称为 logits）中包含非常大的值时，`torch.exp(X)` 的计算结果可能会超出计算机浮点数所能表示的最大范围，导致结果变为无穷大 (`inf`)。\n",
    "\n",
    "正如提示中提到的，我们来试试计算 `exp(50)`：\n",
    "$e^{50} \\approx 5.18 \\times 10^{21}$\n",
    "这个数值本身已经非常巨大。在32位浮点数（PyTorch中`torch.float32`的默认类型）中，能表示的最大值大约是 $3.4 \\times 10^{38}$。虽然`exp(50)`没有直接溢出，但如果输入值再大一些，比如`exp(100)`，其结果约为 $2.68 \\times 10^{43}$，就会立刻导致上溢，返回值变为 `inf`。\n",
    "\n",
    "当这种情况发生时，`softmax`的计算就会变成：\n",
    "$$ \\text{softmax}(\\mathbf{o})_j = \\frac{e^{o_j}}{\\sum_k e^{o_k}} \\rightarrow \\frac{\\infty}{\\infty} $$\n",
    "这个结果在计算中会得到 `NaN` (Not a Number)，导致整个训练过程中的梯度计算等后续步骤全部失效。\n",
    "\n",
    "***\n",
    "\n",
    "### 2. Cross-Entropy 的数值稳定性问题 (下溢)\n",
    "\n",
    "你实现的交叉熵损失函数如下：\n",
    "\n",
    "```python\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])\n",
    "```\n",
    "\n",
    "**问题所在：对数函数的定义域**\n",
    "\n",
    "`torch.log()` 函数的输入必须是正数 ($x > 0$)。`y_hat` 是 `softmax` 函数的输出，理论上是 (0, 1] 范围内的概率值。\n",
    "\n",
    "问题在于，当 `softmax` 的某个输出概率值 `y_hat[i]` 极其接近0时（例如，由于数值精度限制，它可能被计算为0），`torch.log(y_hat[i])` 的结果将是负无穷 (`-inf`)。这被称为**数值下溢 (Numerical Underflow)**（指概率值的下溢）。这同样会给损失计算和梯度传播带来问题，导致梯度爆炸或变为 `NaN`。\n",
    "\n",
    "这种情况通常发生在模型对某个样本的预测“错得离谱”时。例如，模型以接近100%的置信度预测样本属于类别A，但真实标签却是类别B。那么，对于类别B的预测概率 `y_hat[B]` 就会非常接近0，从而导致 `log(y_hat[B])` 计算出问题。\n",
    "\n",
    "***\n",
    "\n",
    "### 3. 针对问题1和2的解决方案\n",
    "\n",
    "一个优雅且在所有深度学习框架中广泛应用的解决方案是将 `softmax` 运算和 `cross-entropy` 损失计算合并到一个函数中。这样做可以利用一个数学技巧来同时解决上溢和下溢问题。\n",
    "\n",
    "**第一步：稳定 Softmax (解决上溢)**\n",
    "\n",
    "为了防止 `exp` 计算时上溢，我们可以利用以下恒等式：\n",
    "$$ \\text{softmax}(\\mathbf{o})_j = \\frac{e^{o_j}}{\\sum_k e^{o_k}} = \\frac{e^{o_j} \\cdot C}{\\sum_k e^{o_k} \\cdot C} = \\frac{e^{o_j + \\log C}}{\\sum_k e^{o_k + \\log C}} $$\n",
    "我们可以选择一个巧妙的常数 $C$，让 $e^{o_j + \\log C}$ 的值保持在合理的范围内。通常，我们选择 $\\log C = -\\max_k(o_k)$。这样，变换后的 logits $\\mathbf{o'}$ 为：\n",
    "$$ o'_j = o_j - \\max_k(o_k) $$\n",
    "此时，$\\mathbf{o'}$ 中的最大值变为了0，所有值都小于等于0。这样再进行 `exp` 计算时，最大的结果是 $e^0=1$，就完全避免了上溢问题。\n",
    "\n",
    "**第二步：合并 Softmax 和 Cross-Entropy (Log-Sum-Exp 技巧)**\n",
    "\n",
    "交叉熵损失的完整计算公式（对于单个样本）是：\n",
    "$$ L = -\\log(\\text{softmax}(\\mathbf{o})_y) = -\\log\\left(\\frac{e^{o_y}}{\\sum_k e^{o_k}}\\right) $$\n",
    "其中 $y$ 是真实类别的索引。利用对数性质，我们可以将其展开：\n",
    "$$ L = - \\left( \\log(e^{o_y}) - \\log\\left(\\sum_k e^{o_k}\\right) \\right) = - \\left( o_y - \\log\\left(\\sum_k e^{o_k}\\right) \\right) = \\log\\left(\\sum_k e^{o_k}\\right) - o_y $$\n",
    "这个 $\\log(\\sum_k e^{o_k})$ 就是著名的 **Log-Sum-Exp** 函数。直接计算它仍然可能因为 $\\sum_k e^{o_k}$ 上溢而出错。但我们可以把第一步的技巧应用在这里：\n",
    "$$ \\log\\left(\\sum_k e^{o_k}\\right) = \\log\\left(\\sum_k e^{o_k - \\max_i(o_i) + \\max_i(o_i)}\\right) = \\log\\left(e^{\\max_i(o_i)} \\sum_k e^{o_k - \\max_i(o_i)}\\right) $$\n",
    "$$ = \\max_i(o_i) + \\log\\left(\\sum_k e^{o_k - \\max_i(o_i)}\\right) $$\n",
    "这个最终形式是数值稳定的。因为 $o_k - \\max_i(o_i) \\le 0$，所以 $e^{o_k - \\max_i(o_i)}$ 不会溢出。\n",
    "\n",
    "**实践中的解决方案：**\n",
    "\n",
    "在 PyTorch 中，我们不需要自己实现这个复杂的稳定版本。我们只需要使用 `torch.nn.CrossEntropyLoss` 即可。 这个损失函数会接收**未经 softmax 处理的原始 logits** 作为输入，并在内部完成所有数值稳定化的计算。\n",
    "\n",
    "```python\n",
    "# 正确的做法\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# ... 在训练循环中 ...\n",
    "# net的最后一层不应包含softmax\n",
    "logits = net(X) \n",
    "# loss_fn 会自动应用 log-softmax\n",
    "loss = loss_fn(logits, y) \n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### 4. Argmax 是否总是最优解？\n",
    "\n",
    "**答案是否定的。**\n",
    "\n",
    "返回概率最大的分类标签（即 `argmax`）是一种决策策略，它隐含地假设**每种错误分类的代价都是相等的**。但在许多现实世界的应用中，这个假设并不成立。\n",
    "\n",
    "**医疗诊断场景的例子：**\n",
    "\n",
    "假设一个模型用于诊断病人是否患有癌症。有两种可能的错误：\n",
    "1.  **假阴性 (False Negative)**: 模型预测病人**健康**，但实际上病人**患有癌症**。这个错误的代价是极高的，可能会导致病人错过最佳治疗时机，甚至危及生命。\n",
    "2.  **假阳性 (False Positive)**: 模型预测病人**患有癌症**，但实际上病人是**健康的**。这个错误的代价相对较低，可能只是让病人接受了不必要的进一步检查（如活检），造成一定的经济负担和心理压力。\n",
    "\n",
    "在这种**代价不对称**的情况下，我们不能简单地使用 `argmax`。 即使模型预测患癌的概率只有 40%（`P(cancer)=0.4`），而健康概率为 60%（`P(healthy)=0.6`），`argmax` 会选择“健康”。但考虑到假阴性的巨大风险，一个负责任的医生或系统可能会选择将该病人标记为“高风险”，并建议进行进一步检查。\n",
    "\n",
    "在这种场景下，决策的依据应该结合模型的概率输出和不同错误的代价，而不是单纯地选择概率最高的那个。我们可能会调整决策阈值，或者更关注**召回率 (Recall)** 这类更能反映模型识别出所有正例能力的指标。\n",
    "\n",
    "***\n",
    "\n",
    "### 5. 大词汇量对 Softmax 回归的挑战\n",
    "\n",
    "假设我们用 Softmax 回归来构建一个语言模型，预测下一个单词。这里的“可选取的单词数目”就是词汇表的大小（`vocab_size`），它对应于 Softmax 层的输出类别数。当 `vocab_size` 非常大时（例如，几十万甚至上百万），会带来以下主要问题：\n",
    "\n",
    "1.  **计算成本高昂**：Softmax 回归的最后一步是一个线性层，其权重矩阵 `W` 的维度是 `(hidden_size, vocab_size)`。\n",
    "    *   **前向传播**：计算 `logits = hidden_state @ W` 的矩阵乘法非常耗时。如果 `hidden_size` 是 512，`vocab_size` 是 50000，这个乘法就需要 `512 * 50000` 次乘加运算。\n",
    "    *   **反向传播**：计算梯度同样需要大量的计算。\n",
    "\n",
    "2.  **内存占用巨大**：存储这个巨大的权重矩阵 `W` 需要大量的内存（尤其是 GPU 显存）。以上述例子计算，仅存储这个矩阵就需要 `512 * 50000 * 4` 字节（假设是32位浮点数） $\\approx$ 102 MB 的空间。对于更大的模型和词汇表，这会成为一个严重的瓶颈。\n",
    "\n",
    "3.  **训练效率低下（数据稀疏性）**：对于一个庞大的词汇表，很多词（尤其是罕见词）在训练数据中出现的次数非常少。这意味着模型很难学习到这些罕见词的良好表示，导致对这些词的预测效果很差。在每次更新中，只有对应正确单词的那个输出权重才会被有效更新，大部分计算都是“浪费”的。\n",
    "\n",
    "为了解决这些问题，研究人员开发了多种替代方案，如**分层 Softmax (Hierarchical Softmax)** 和**负采样 (Negative Sampling)** 等技术，它们通过近似计算来降低计算复杂性。"
   ],
   "id": "125ec21fead98da4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
